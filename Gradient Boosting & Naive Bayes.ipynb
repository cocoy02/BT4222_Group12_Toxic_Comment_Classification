{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fccde4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, log_loss,roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# for lightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# for naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# for evaluation metrics\n",
    "%run -i helper_functions.py\n",
    "\n",
    "# for multi-label classification\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f96bc211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "      <th>min_length_scaled</th>\n",
       "      <th>num_words_vs_length</th>\n",
       "      <th>exclamation_marks_vs_length</th>\n",
       "      <th>num_unique_words_scaled</th>\n",
       "      <th>verbs_vs_length</th>\n",
       "      <th>num_uppercase_scaled</th>\n",
       "      <th>uppercase_vs_length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bad_toxic_vs_length</th>\n",
       "      <th>bad_severe_toxic_vs_length</th>\n",
       "      <th>bad_obscene_vs_length</th>\n",
       "      <th>bad_threat_vs_length</th>\n",
       "      <th>bad_insult_vs_length</th>\n",
       "      <th>bad_identity_hate_vs_length</th>\n",
       "      <th>29</th>\n",
       "      <th>34</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>65</th>\n",
       "      <th>72</th>\n",
       "      <th>82</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>93</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>98</th>\n",
       "      <th>100</th>\n",
       "      <th>103</th>\n",
       "      <th>105</th>\n",
       "      <th>114</th>\n",
       "      <th>132</th>\n",
       "      <th>135</th>\n",
       "      <th>139</th>\n",
       "      <th>143</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>170</th>\n",
       "      <th>198</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.181132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106329</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.064151</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054548</td>\n",
       "      <td>-0.105844</td>\n",
       "      <td>-0.023651</td>\n",
       "      <td>-0.120931</td>\n",
       "      <td>0.029694</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.138915</td>\n",
       "      <td>-0.011885</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>-0.030327</td>\n",
       "      <td>-0.030858</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>-0.074290</td>\n",
       "      <td>0.075012</td>\n",
       "      <td>-0.009385</td>\n",
       "      <td>0.039875</td>\n",
       "      <td>-0.091320</td>\n",
       "      <td>-0.017755</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>-0.199211</td>\n",
       "      <td>-0.109984</td>\n",
       "      <td>0.089084</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>-0.019501</td>\n",
       "      <td>-0.091946</td>\n",
       "      <td>-0.113697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104774</td>\n",
       "      <td>-0.020276</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>-0.146403</td>\n",
       "      <td>0.014844</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>0.092921</td>\n",
       "      <td>-0.116742</td>\n",
       "      <td>0.059807</td>\n",
       "      <td>-0.077983</td>\n",
       "      <td>-0.097744</td>\n",
       "      <td>-0.097991</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>0.115281</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.122598</td>\n",
       "      <td>-0.118445</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>-0.067295</td>\n",
       "      <td>-0.079366</td>\n",
       "      <td>-0.044959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091139</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022507</td>\n",
       "      <td>-0.155533</td>\n",
       "      <td>0.175771</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>-0.035649</td>\n",
       "      <td>-0.149408</td>\n",
       "      <td>0.170970</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.162394</td>\n",
       "      <td>0.067722</td>\n",
       "      <td>-0.108610</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>0.072878</td>\n",
       "      <td>-0.015372</td>\n",
       "      <td>0.148674</td>\n",
       "      <td>-0.131555</td>\n",
       "      <td>-0.060714</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>-0.029582</td>\n",
       "      <td>-0.146134</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.036539</td>\n",
       "      <td>-0.053628</td>\n",
       "      <td>0.027530</td>\n",
       "      <td>-0.211230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.175719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141772</td>\n",
       "      <td>0.036741</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.017572</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028492</td>\n",
       "      <td>-0.103913</td>\n",
       "      <td>0.071215</td>\n",
       "      <td>-0.131409</td>\n",
       "      <td>0.066988</td>\n",
       "      <td>-0.070037</td>\n",
       "      <td>0.184324</td>\n",
       "      <td>0.047017</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.044984</td>\n",
       "      <td>-0.149924</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>-0.038304</td>\n",
       "      <td>0.050073</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.091080</td>\n",
       "      <td>-0.145382</td>\n",
       "      <td>-0.004285</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.134984</td>\n",
       "      <td>-0.214832</td>\n",
       "      <td>0.177560</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>-0.087473</td>\n",
       "      <td>0.106848</td>\n",
       "      <td>-0.015987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078496</td>\n",
       "      <td>-0.047719</td>\n",
       "      <td>0.130365</td>\n",
       "      <td>-0.037535</td>\n",
       "      <td>-0.104838</td>\n",
       "      <td>0.131475</td>\n",
       "      <td>0.138012</td>\n",
       "      <td>0.020882</td>\n",
       "      <td>0.027521</td>\n",
       "      <td>-0.151158</td>\n",
       "      <td>-0.135344</td>\n",
       "      <td>0.050743</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>-0.008789</td>\n",
       "      <td>-0.115800</td>\n",
       "      <td>0.190293</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>-0.204627</td>\n",
       "      <td>0.162032</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>-0.221076</td>\n",
       "      <td>0.163578</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>-0.031184</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>0.038566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  none  \\\n",
       "0      0             0        0       0       0              0     1   \n",
       "1      0             0        0       0       0              0     1   \n",
       "2      0             0        0       0       0              0     1   \n",
       "3      0             0        0       0       0              0     1   \n",
       "4      0             0        0       0       0              0     1   \n",
       "\n",
       "   min_length_scaled  num_words_vs_length  exclamation_marks_vs_length  \\\n",
       "0           0.009393             0.181132                     0.000000   \n",
       "1           0.000723             0.160714                     0.008929   \n",
       "2           0.007225             0.188841                     0.000000   \n",
       "3           0.007948             0.175719                     0.000000   \n",
       "4           0.003613             0.208955                     0.000000   \n",
       "\n",
       "   num_unique_words_scaled  verbs_vs_length  num_uppercase_scaled  \\\n",
       "0                 0.106329         0.041509              0.003426   \n",
       "1                 0.043038         0.026786              0.001612   \n",
       "2                 0.091139         0.038627              0.000806   \n",
       "3                 0.141772         0.036741              0.002217   \n",
       "4                 0.027848         0.059701              0.000403   \n",
       "\n",
       "   uppercase_vs_length  sentiment  bad_toxic_vs_length  \\\n",
       "0             0.064151     0.5574                  0.0   \n",
       "1             0.071429     0.2942                  0.0   \n",
       "2             0.017167    -0.1779                  0.0   \n",
       "3             0.017572     0.5106                  0.0   \n",
       "4             0.029851     0.6808                  0.0   \n",
       "\n",
       "   bad_severe_toxic_vs_length  bad_obscene_vs_length  bad_threat_vs_length  \\\n",
       "0                         0.0                    0.0                   0.0   \n",
       "1                         0.0                    0.0                   0.0   \n",
       "2                         0.0                    0.0                   0.0   \n",
       "3                         0.0                    0.0                   0.0   \n",
       "4                         0.0                    0.0                   0.0   \n",
       "\n",
       "   bad_insult_vs_length  bad_identity_hate_vs_length        29        34  \\\n",
       "0                   0.0                          0.0 -0.054548 -0.105844   \n",
       "1                   0.0                          0.0  0.104774 -0.020276   \n",
       "2                   0.0                          0.0  0.022507 -0.155533   \n",
       "3                   0.0                          0.0  0.028492 -0.103913   \n",
       "4                   0.0                          0.0  0.078496 -0.047719   \n",
       "\n",
       "         46        47        53        54        65        72        82  \\\n",
       "0 -0.023651 -0.120931  0.029694  0.000656  0.138915 -0.011885  0.066578   \n",
       "1  0.102398 -0.146403  0.014844  0.019279  0.066769  0.092921 -0.116742   \n",
       "2  0.175771  0.021757 -0.035649 -0.149408  0.170970  0.032876  0.040762   \n",
       "3  0.071215 -0.131409  0.066988 -0.070037  0.184324  0.047017  0.000166   \n",
       "4  0.130365 -0.037535 -0.104838  0.131475  0.138012  0.020882  0.027521   \n",
       "\n",
       "         86        87        93        95        96        98       100  \\\n",
       "0 -0.030327 -0.030858  0.003075 -0.001155 -0.074290  0.075012 -0.009385   \n",
       "1  0.059807 -0.077983 -0.097744 -0.097991  0.028930  0.115281  0.009460   \n",
       "2 -0.089416 -0.162394  0.067722 -0.108610 -0.030535  0.072878 -0.015372   \n",
       "3 -0.044984 -0.149924  0.042974 -0.038304  0.050073  0.022973  0.005240   \n",
       "4 -0.151158 -0.135344  0.050743 -0.000602  0.006453 -0.008789 -0.115800   \n",
       "\n",
       "        103       105       114       132       135       139       143  \\\n",
       "0  0.039875 -0.091320 -0.017755  0.003997 -0.199211 -0.109984  0.089084   \n",
       "1  0.122598 -0.118445  0.039541  0.017522  0.001397  0.000094  0.021135   \n",
       "2  0.148674 -0.131555 -0.060714  0.026459 -0.029582 -0.146134  0.109907   \n",
       "3  0.091080 -0.145382 -0.004285 -0.000706 -0.134984 -0.214832  0.177560   \n",
       "4  0.190293  0.007073 -0.204627  0.162032  0.013798 -0.221076  0.163578   \n",
       "\n",
       "        156       157       170       198  \n",
       "0  0.012651 -0.019501 -0.091946 -0.113697  \n",
       "1  0.039308 -0.067295 -0.079366 -0.044959  \n",
       "2  0.036539 -0.053628  0.027530 -0.211230  \n",
       "3  0.007675 -0.087473  0.106848 -0.015987  \n",
       "4 -0.068310 -0.031184 -0.017280  0.038566  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the train dataset\n",
    "selected_train = pd.read_csv('Data/selected_train.csv')\n",
    "selected_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a47f7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>min_length_scaled</th>\n",
       "      <th>num_words_vs_length</th>\n",
       "      <th>exclamation_marks_vs_length</th>\n",
       "      <th>num_unique_words_scaled</th>\n",
       "      <th>verbs_vs_length</th>\n",
       "      <th>num_uppercase_scaled</th>\n",
       "      <th>uppercase_vs_length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bad_toxic_vs_length</th>\n",
       "      <th>bad_severe_toxic_vs_length</th>\n",
       "      <th>bad_obscene_vs_length</th>\n",
       "      <th>bad_threat_vs_length</th>\n",
       "      <th>bad_insult_vs_length</th>\n",
       "      <th>bad_identity_hate_vs_length</th>\n",
       "      <th>29</th>\n",
       "      <th>34</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>65</th>\n",
       "      <th>72</th>\n",
       "      <th>82</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>93</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>98</th>\n",
       "      <th>100</th>\n",
       "      <th>103</th>\n",
       "      <th>105</th>\n",
       "      <th>114</th>\n",
       "      <th>132</th>\n",
       "      <th>135</th>\n",
       "      <th>139</th>\n",
       "      <th>143</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>170</th>\n",
       "      <th>198</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052982</td>\n",
       "      <td>-0.169101</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>-0.231872</td>\n",
       "      <td>-0.147303</td>\n",
       "      <td>0.085074</td>\n",
       "      <td>0.279414</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>0.216464</td>\n",
       "      <td>-0.070892</td>\n",
       "      <td>-0.137326</td>\n",
       "      <td>0.045426</td>\n",
       "      <td>-0.138258</td>\n",
       "      <td>0.062082</td>\n",
       "      <td>0.168577</td>\n",
       "      <td>-0.144716</td>\n",
       "      <td>0.115447</td>\n",
       "      <td>-0.123190</td>\n",
       "      <td>0.040738</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>-0.158238</td>\n",
       "      <td>-0.204194</td>\n",
       "      <td>0.116565</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>-0.206160</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>-0.036748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>0.194164</td>\n",
       "      <td>0.005340</td>\n",
       "      <td>-0.175857</td>\n",
       "      <td>0.152049</td>\n",
       "      <td>0.067513</td>\n",
       "      <td>0.093680</td>\n",
       "      <td>0.433347</td>\n",
       "      <td>-0.139590</td>\n",
       "      <td>-0.156423</td>\n",
       "      <td>0.379176</td>\n",
       "      <td>-0.015764</td>\n",
       "      <td>-0.018882</td>\n",
       "      <td>0.210565</td>\n",
       "      <td>-0.238187</td>\n",
       "      <td>0.241806</td>\n",
       "      <td>-0.004935</td>\n",
       "      <td>-0.013467</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>-0.117174</td>\n",
       "      <td>-0.075475</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>-0.148617</td>\n",
       "      <td>-0.350740</td>\n",
       "      <td>0.113815</td>\n",
       "      <td>-0.070907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.149554</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.118987</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-0.7393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.132685</td>\n",
       "      <td>0.156570</td>\n",
       "      <td>-0.122877</td>\n",
       "      <td>-0.041197</td>\n",
       "      <td>-0.045822</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>-0.012794</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>-0.184707</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>-0.047319</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.065742</td>\n",
       "      <td>-0.074447</td>\n",
       "      <td>0.009821</td>\n",
       "      <td>-0.114241</td>\n",
       "      <td>-0.125080</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>-0.119656</td>\n",
       "      <td>-0.274707</td>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.100782</td>\n",
       "      <td>-0.107205</td>\n",
       "      <td>-0.050780</td>\n",
       "      <td>-0.098343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.169661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.079840</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.088192</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.220622</td>\n",
       "      <td>0.163259</td>\n",
       "      <td>0.237079</td>\n",
       "      <td>0.203803</td>\n",
       "      <td>-0.036898</td>\n",
       "      <td>-0.085977</td>\n",
       "      <td>0.060488</td>\n",
       "      <td>-0.030683</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.092577</td>\n",
       "      <td>0.084728</td>\n",
       "      <td>-0.005106</td>\n",
       "      <td>-0.241482</td>\n",
       "      <td>-0.023304</td>\n",
       "      <td>-0.005002</td>\n",
       "      <td>-0.281848</td>\n",
       "      <td>-0.157011</td>\n",
       "      <td>0.184323</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>-0.066242</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>-0.111269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.167665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104646</td>\n",
       "      <td>-0.068364</td>\n",
       "      <td>-0.012882</td>\n",
       "      <td>-0.102120</td>\n",
       "      <td>0.041755</td>\n",
       "      <td>-0.031094</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>0.158524</td>\n",
       "      <td>0.137380</td>\n",
       "      <td>0.068439</td>\n",
       "      <td>-0.086570</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>-0.114363</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.029552</td>\n",
       "      <td>0.054780</td>\n",
       "      <td>0.124478</td>\n",
       "      <td>-0.192200</td>\n",
       "      <td>0.055657</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>-0.181419</td>\n",
       "      <td>-0.165707</td>\n",
       "      <td>0.194511</td>\n",
       "      <td>0.143557</td>\n",
       "      <td>-0.059017</td>\n",
       "      <td>0.136676</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0      0             0        0       0       0              0   \n",
       "1      0             0        0       0       0              0   \n",
       "2      0             0        0       0       0              0   \n",
       "3      0             0        0       0       0              0   \n",
       "4      0             0        0       0       0              0   \n",
       "\n",
       "   min_length_scaled  num_words_vs_length  exclamation_marks_vs_length  \\\n",
       "0           0.002890             0.166667                     0.000000   \n",
       "1           0.005058             0.187500                     0.000000   \n",
       "2           0.000723             0.149554                     0.002232   \n",
       "3           0.007225             0.169661                     0.000000   \n",
       "4           0.003613             0.167665                     0.000000   \n",
       "\n",
       "   num_unique_words_scaled  verbs_vs_length  num_uppercase_scaled  \\\n",
       "0                 0.032911         0.031250              0.000403   \n",
       "1                 0.015190         0.031250              0.000202   \n",
       "2                 0.118987         0.031250              0.002821   \n",
       "3                 0.070886         0.029940              0.008061   \n",
       "4                 0.060759         0.035928              0.000806   \n",
       "\n",
       "   uppercase_vs_length  sentiment  bad_toxic_vs_length  \\\n",
       "0             0.020833     0.3612                  0.0   \n",
       "1             0.031250     0.0516                  0.0   \n",
       "2             0.031250    -0.7393                  0.0   \n",
       "3             0.079840     0.0258                  0.0   \n",
       "4             0.011976     0.7184                  0.0   \n",
       "\n",
       "   bad_severe_toxic_vs_length  bad_obscene_vs_length  bad_threat_vs_length  \\\n",
       "0                         0.0                    0.0                   0.0   \n",
       "1                         0.0                    0.0                   0.0   \n",
       "2                         0.0                    0.0                   0.0   \n",
       "3                         0.0                    0.0                   0.0   \n",
       "4                         0.0                    0.0                   0.0   \n",
       "\n",
       "   bad_insult_vs_length  bad_identity_hate_vs_length        29        34  \\\n",
       "0                   0.0                          0.0 -0.052982 -0.169101   \n",
       "1                   0.0                          0.0  0.032172  0.046765   \n",
       "2                   0.0                          0.0  0.000621 -0.132685   \n",
       "3                   0.0                          0.0  0.079728  0.022776   \n",
       "4                   0.0                          0.0  0.104646 -0.068364   \n",
       "\n",
       "         46        47        53        54        65        72        82  \\\n",
       "0  0.104210 -0.231872 -0.147303  0.085074  0.279414  0.045263  0.216464   \n",
       "1  0.194164  0.005340 -0.175857  0.152049  0.067513  0.093680  0.433347   \n",
       "2  0.156570 -0.122877 -0.041197 -0.045822  0.151609 -0.012794  0.058626   \n",
       "3  0.088192 -0.004380  0.004026 -0.220622  0.163259  0.237079  0.203803   \n",
       "4 -0.012882 -0.102120  0.041755 -0.031094  0.149613  0.158524  0.137380   \n",
       "\n",
       "         86        87        93        95        96        98       100  \\\n",
       "0 -0.070892 -0.137326  0.045426 -0.138258  0.062082  0.168577 -0.144716   \n",
       "1 -0.139590 -0.156423  0.379176 -0.015764 -0.018882  0.210565 -0.238187   \n",
       "2  0.027053 -0.184707  0.032653 -0.047319  0.004221  0.065742 -0.074447   \n",
       "3 -0.036898 -0.085977  0.060488 -0.030683  0.002059  0.092577  0.084728   \n",
       "4  0.068439 -0.086570  0.027189 -0.114363  0.001011 -0.029552  0.054780   \n",
       "\n",
       "        103       105       114       132       135       139       143  \\\n",
       "0  0.115447 -0.123190  0.040738 -0.010083 -0.158238 -0.204194  0.116565   \n",
       "1  0.241806 -0.004935 -0.013467  0.003550 -0.117174 -0.075475  0.043945   \n",
       "2  0.009821 -0.114241 -0.125080  0.045087 -0.119656 -0.274707  0.102546   \n",
       "3 -0.005106 -0.241482 -0.023304 -0.005002 -0.281848 -0.157011  0.184323   \n",
       "4  0.124478 -0.192200  0.055657  0.024936 -0.181419 -0.165707  0.194511   \n",
       "\n",
       "        156       157       170       198  none  \n",
       "0  0.098296 -0.206160  0.046779 -0.036748     1  \n",
       "1 -0.148617 -0.350740  0.113815 -0.070907     1  \n",
       "2  0.100782 -0.107205 -0.050780 -0.098343     1  \n",
       "3  0.067625 -0.066242  0.023737 -0.111269     1  \n",
       "4  0.143557 -0.059017  0.136676 -0.004530     1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the test dataset\n",
    "selected_test = pd.read_csv('Data/selected_test.csv')\n",
    "selected_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b68e56c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "features = selected_train.columns[7:].tolist()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed6757",
   "metadata": {},
   "source": [
    "## Gradient Boosting (LGBMClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d104cd",
   "metadata": {},
   "source": [
    "### Baseline Gradient Boosting using BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "673b70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gb = BinaryRelevance(LGBMClassifier(random_state=0))\n",
    "# train\n",
    "classifier_gb.fit(selected_train[features], selected_train[labels])\n",
    "# predict\n",
    "predictions_gb = classifier_gb.predict(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b52ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "predictions_proba_gb = classifier_gb.predict_proba(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a5d6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9324626655219307\n",
      "Precision score:  0.8585256861860837\n",
      "Recall score:  0.7201834862385321\n",
      "F1 score:  0.7820014889765815\n",
      "Confusion matrix for label toxic:\n",
      "[[142777   1500]\n",
      " [  4464  10830]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[157808    168]\n",
      " [   477   1118]]\n",
      "Confusion matrix for label obscene:\n",
      "[[150046   1076]\n",
      " [  1836   6613]]\n",
      "Confusion matrix for label threat:\n",
      "[[159055     38]\n",
      " [    50    428]]\n",
      "Confusion matrix for label insult:\n",
      "[[150390   1304]\n",
      " [  2335   5542]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[158060    106]\n",
      " [   659    746]]\n",
      "Logarithmic Loss:  0.2437155281367502\n",
      "ROC AUC score:  0.9860905444013781\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "get_evaluation_score(selected_train[labels], predictions_gb, predictions_proba_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bb80f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8789896526931132\n",
      "Precision score:  0.5829492803206758\n",
      "Recall score:  0.6643674989653745\n",
      "F1 score:  0.6174134411558834\n",
      "Confusion matrix for label toxic:\n",
      "[[54806  3082]\n",
      " [ 1502  4588]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[63254   357]\n",
      " [  220   147]]\n",
      "Confusion matrix for label obscene:\n",
      "[[58600  1687]\n",
      " [ 1071  2620]]\n",
      "Confusion matrix for label threat:\n",
      "[[63381   386]\n",
      " [  156    55]]\n",
      "Confusion matrix for label insult:\n",
      "[[59351  1200]\n",
      " [ 1367  2060]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[62992   274]\n",
      " [  550   162]]\n",
      "Logarithmic Loss:  0.3109336144201333\n",
      "ROC AUC score:  0.9583558250719668\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "predictions_gb_test = classifier_gb.predict(selected_test[features])\n",
    "predictions_proba_gb_test = classifier_gb.predict_proba(selected_test[features])\n",
    "get_evaluation_score(selected_test[labels], predictions_gb_test, predictions_proba_gb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dbf73",
   "metadata": {},
   "source": [
    "### Baseline Gradient Boosting using ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1c56a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chain_gb = ClassifierChain(LGBMClassifier(random_state=0))\n",
    "# train\n",
    "classifier_chain_gb.fit(selected_train[features], selected_train[labels])\n",
    "# predict\n",
    "predictions_chain_gb = classifier_chain_gb.predict(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "033ed52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "predictions_proba_chain_gb = classifier_chain_gb.predict_proba(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75ce7713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9344868428473846\n",
      "Precision score:  0.8403138050122246\n",
      "Recall score:  0.7235170095162118\n",
      "F1 score:  0.775799218354555\n",
      "Confusion matrix for label toxic:\n",
      "[[142777   1500]\n",
      " [  4464  10830]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[157818    158]\n",
      " [   458   1137]]\n",
      "Confusion matrix for label obscene:\n",
      "[[149876   1246]\n",
      " [  1717   6732]]\n",
      "Confusion matrix for label threat:\n",
      "[[158951    142]\n",
      " [   198    280]]\n",
      "Confusion matrix for label insult:\n",
      "[[150017   1677]\n",
      " [  2165   5712]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[157990    176]\n",
      " [   702    703]]\n",
      "Logarithmic Loss:  0.27562349981689854\n",
      "ROC AUC score:  0.98159005455481\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "get_evaluation_score(selected_train[labels], predictions_chain_gb, predictions_proba_chain_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "965d64a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8797868017130889\n",
      "Precision score:  0.5570072116149407\n",
      "Recall score:  0.6842323079045386\n",
      "F1 score:  0.612636197875275\n",
      "Confusion matrix for label toxic:\n",
      "[[54806  3082]\n",
      " [ 1502  4588]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[63268   343]\n",
      " [  209   158]]\n",
      "Confusion matrix for label obscene:\n",
      "[[58263  2024]\n",
      " [  965  2726]]\n",
      "Confusion matrix for label threat:\n",
      "[[63426   341]\n",
      " [  150    61]]\n",
      "Confusion matrix for label insult:\n",
      "[[58812  1739]\n",
      " [ 1222  2205]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[62931   335]\n",
      " [  530   182]]\n",
      "Logarithmic Loss:  0.33110831807467267\n",
      "ROC AUC score:  0.9556995692510866\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "predictions_chain_gb_test = classifier_chain_gb.predict(selected_test[features])\n",
    "predictions_proba_chain_gb_test = classifier_chain_gb.predict_proba(selected_test[features])\n",
    "get_evaluation_score(selected_test[labels], predictions_chain_gb_test, predictions_proba_chain_gb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d114f6e",
   "metadata": {},
   "source": [
    "### Baseline Gradient Boosting using LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "220e7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_powerset_gb = LabelPowerset(LGBMClassifier(random_state=0))\n",
    "# train\n",
    "classifier_powerset_gb.fit(selected_train[features], selected_train[labels])\n",
    "# predict\n",
    "predictions_powerset_gb = classifier_powerset_gb.predict(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00a76511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "predictions_proba_powerset_gb = classifier_powerset_gb.predict_proba(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18e266da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7406358298187014\n",
      "Precision score:  0.09740660064706258\n",
      "Recall score:  0.17445438486523449\n",
      "F1 score:  0.12454536249158364\n",
      "Confusion matrix for label toxic:\n",
      "[[122517  21760]\n",
      " [ 12063   3231]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[153105   4871]\n",
      " [  1563     32]]\n",
      "Confusion matrix for label obscene:\n",
      "[[136712  14410]\n",
      " [  6960   1489]]\n",
      "Confusion matrix for label threat:\n",
      "[[151307   7786]\n",
      " [   474      4]]\n",
      "Confusion matrix for label insult:\n",
      "[[136507  15187]\n",
      " [  6551   1326]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[149986   8180]\n",
      " [  1364     41]]\n",
      "Logarithmic Loss:  0.8053150175420156\n",
      "ROC AUC score:  0.5289704923713838\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "get_evaluation_score(selected_train[labels], predictions_powerset_gb, predictions_proba_powerset_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30a1f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7441307949607677\n",
      "Precision score:  0.10160540877173552\n",
      "Recall score:  0.1799558559801352\n",
      "F1 score:  0.12966069946135153\n",
      "Confusion matrix for label toxic:\n",
      "[[48915  8973]\n",
      " [ 4753  1337]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[61842  1769]\n",
      " [  362     5]]\n",
      "Confusion matrix for label obscene:\n",
      "[[54521  5766]\n",
      " [ 3037   654]]\n",
      "Confusion matrix for label threat:\n",
      "[[60954  2813]\n",
      " [  210     1]]\n",
      "Confusion matrix for label insult:\n",
      "[[54379  6172]\n",
      " [ 2828   599]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[60239  3027]\n",
      " [  699    13]]\n",
      "Logarithmic Loss:  0.8015398931821524\n",
      "ROC AUC score:  0.5309322488614058\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "predictions_powerset_gb_test = classifier_powerset_gb.predict(selected_test[features])\n",
    "predictions_proba_powerset_gb_test = classifier_powerset_gb.predict_proba(selected_test[features])\n",
    "get_evaluation_score(selected_test[labels], predictions_powerset_gb_test, predictions_proba_powerset_gb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86eb47",
   "metadata": {},
   "source": [
    "### Baseline Gradient Boosting using OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "22b908d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing toxic comments...**\n",
      "Test accuracy is 0.9283503704398387\n",
      "Test precision is 0.598174706649283\n",
      "Test f1-score is 0.666860465116279\n",
      "Test recall is 0.7533661740558292\n",
      "[[54806  3082]\n",
      " [ 1502  4588]]\n",
      "Test logarithmic loss is 2.5825144133250966\n",
      "Test ROC-AUC score is 0.8500627166575443\n",
      "\n",
      "\n",
      "**Processing severe_toxic comments...**\n",
      "Test accuracy is 0.9909812748132171\n",
      "Test precision is 0.2916666666666667\n",
      "Test f1-score is 0.3375430539609644\n",
      "Test recall is 0.40054495912806537\n",
      "[[63254   357]\n",
      " [  220   147]]\n",
      "Test logarithmic loss is 0.32506780464410595\n",
      "Test ROC-AUC score is 0.6974663611253978\n",
      "\n",
      "\n",
      "**Processing obscene comments...**\n",
      "Test accuracy is 0.9568914314295539\n",
      "Test precision is 0.6083120501509172\n",
      "Test f1-score is 0.655163790947737\n",
      "Test recall is 0.7098347331346518\n",
      "[[58600  1687]\n",
      " [ 1071  2620]]\n",
      "Test logarithmic loss is 1.5537903036541485\n",
      "Test ROC-AUC score is 0.840925958801141\n",
      "\n",
      "\n",
      "**Processing threat comments...**\n",
      "Test accuracy is 0.9915283378661415\n",
      "Test precision is 0.12471655328798185\n",
      "Test f1-score is 0.16871165644171782\n",
      "Test recall is 0.26066350710900477\n",
      "[[63381   386]\n",
      " [  156    55]]\n",
      "Test logarithmic loss is 0.3053496535825051\n",
      "Test ROC-AUC score is 0.6273051096791435\n",
      "\n",
      "\n",
      "**Processing insult comments...**\n",
      "Test accuracy is 0.9598768326612273\n",
      "Test precision is 0.6319018404907976\n",
      "Test f1-score is 0.6161208314640346\n",
      "Test recall is 0.6011088415523782\n",
      "[[59351  1200]\n",
      " [ 1367  2060]]\n",
      "Test logarithmic loss is 1.4461855364322695\n",
      "Test ROC-AUC score is 0.7906454184475736\n",
      "\n",
      "\n",
      "**Processing identity_hate comments...**\n",
      "Test accuracy is 0.9871205726968646\n",
      "Test precision is 0.37155963302752293\n",
      "Test f1-score is 0.2822299651567944\n",
      "Test recall is 0.22752808988764045\n",
      "[[62992   274]\n",
      " [  550   162]]\n",
      "Test logarithmic loss is 0.4642216135645464\n",
      "Test ROC-AUC score is 0.6115985848230602\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using pipeline for applying lgbm and one vs rest classifier\n",
    "LGBM_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LGBMClassifier(), n_jobs=-1)),\n",
    "            ])\n",
    "for category in labels:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LGBM_pipeline.fit(selected_train[features], selected_train[category])\n",
    "    \n",
    "    # calculating test accuracy (on test dataset)\n",
    "    prediction = LGBM_pipeline.predict(selected_test[features])\n",
    "    print('Test accuracy is {}'.format(accuracy_score(selected_test[category], prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(selected_test[category], prediction)))\n",
    "    print('Test f1-score is {}'.format(f1_score(selected_test[category], prediction)))\n",
    "    print('Test recall is {}'.format(recall_score(selected_test[category], prediction)))\n",
    "    print(confusion_matrix(selected_test[category], prediction))\n",
    "    print('Test logarithmic loss is {}'.format(log_loss(selected_test[category], prediction)))\n",
    "    print('Test ROC-AUC score is {}'.format(roc_auc_score(selected_test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0251c",
   "metadata": {},
   "source": [
    "## Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02fc37",
   "metadata": {},
   "source": [
    "### Baseline Naive Bayes using BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "40c1d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier_nb = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier_nb.fit(selected_train[features], selected_train[labels])\n",
    "# predict\n",
    "predictions_nb = classifier_nb.predict(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2872c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "predictions_proba_nb = classifier_nb.predict_proba(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a064ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8792637759993984\n",
      "Precision score:  0.5580383909328479\n",
      "Recall score:  0.6486124565502308\n",
      "F1 score:  0.577292473981047\n",
      "Confusion matrix for label toxic:\n",
      "[[140351   3926]\n",
      " [  5871   9423]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[152083   5893]\n",
      " [   292   1303]]\n",
      "Confusion matrix for label obscene:\n",
      "[[146146   4976]\n",
      " [  2527   5922]]\n",
      "Confusion matrix for label threat:\n",
      "[[151647   7446]\n",
      " [   181    297]]\n",
      "Confusion matrix for label insult:\n",
      "[[146219   5475]\n",
      " [  2896   4981]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[150542   7624]\n",
      " [   566    839]]\n",
      "Logarithmic Loss:  0.7660158339188156\n",
      "ROC AUC score:  0.9312601005621751\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "get_evaluation_score(selected_train[labels], predictions_nb, predictions_proba_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4cef9914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8374284910437964\n",
      "Precision score:  0.39914770987296333\n",
      "Recall score:  0.7291350531107739\n",
      "F1 score:  0.5031102162203966\n",
      "Confusion matrix for label toxic:\n",
      "[[53390  4498]\n",
      " [ 1571  4519]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[59159  4452]\n",
      " [   68   299]]\n",
      "Confusion matrix for label obscene:\n",
      "[[55923  4364]\n",
      " [  942  2749]]\n",
      "Confusion matrix for label threat:\n",
      "[[59377  4390]\n",
      " [   53   158]]\n",
      "Confusion matrix for label insult:\n",
      "[[56254  4297]\n",
      " [ 1066  2361]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[58234  5032]\n",
      " [  227   485]]\n",
      "Logarithmic Loss:  0.70881977326765\n",
      "ROC AUC score:  0.9267265814152312\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "predictions_nb_test = classifier_nb.predict(selected_test[features])\n",
    "predictions_proba_nb_test = classifier_nb.predict_proba(selected_test[features])\n",
    "get_evaluation_score(selected_test[labels], predictions_nb_test, predictions_proba_nb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b3c27",
   "metadata": {},
   "source": [
    "### Baseline  Naive Bayes using ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3ca4cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier_chain_nb = ClassifierChain(GaussianNB())\n",
    "# train\n",
    "classifier_chain_nb.fit(selected_train[features], selected_train[labels])\n",
    "# predict\n",
    "predictions_chain_nb = classifier_chain_nb.predict(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd4ced26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "predictions_proba_chain_nb = classifier_chain_nb.predict_proba(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6433ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8788125661931052\n",
      "Precision score:  0.5565655674617817\n",
      "Recall score:  0.67795885805459\n",
      "F1 score:  0.5823247163434749\n",
      "Confusion matrix for label toxic:\n",
      "[[140351   3926]\n",
      " [  5871   9423]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[149947   8029]\n",
      " [   182   1413]]\n",
      "Confusion matrix for label obscene:\n",
      "[[145923   5199]\n",
      " [  2302   6147]]\n",
      "Confusion matrix for label threat:\n",
      "[[149029  10064]\n",
      " [   143    335]]\n",
      "Confusion matrix for label insult:\n",
      "[[145785   5909]\n",
      " [  2440   5437]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[148149  10017]\n",
      " [   365   1040]]\n",
      "Logarithmic Loss:  0.6688595094005957\n",
      "ROC AUC score:  0.931072059247107\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "get_evaluation_score(selected_train[labels], predictions_chain_nb, predictions_proba_chain_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca1c9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8373503391790929\n",
      "Precision score:  0.394723171539833\n",
      "Recall score:  0.7618981928541868\n",
      "F1 score:  0.5036299318614065\n",
      "Confusion matrix for label toxic:\n",
      "[[53390  4498]\n",
      " [ 1571  4519]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[57894  5717]\n",
      " [   44   323]]\n",
      "Confusion matrix for label obscene:\n",
      "[[55651  4636]\n",
      " [  842  2849]]\n",
      "Confusion matrix for label threat:\n",
      "[[57428  6339]\n",
      " [   34   177]]\n",
      "Confusion matrix for label insult:\n",
      "[[55645  4906]\n",
      " [  848  2579]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[56704  6562]\n",
      " [  113   599]]\n",
      "Logarithmic Loss:  0.6631063220237972\n",
      "ROC AUC score:  0.9251122828319055\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "predictions_chain_nb_test = classifier_chain_nb.predict(selected_test[features])\n",
    "predictions_proba_chain_nb_test = classifier_chain_nb.predict_proba(selected_test[features])\n",
    "get_evaluation_score(selected_test[labels], predictions_chain_nb_test, predictions_proba_chain_nb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4288d",
   "metadata": {},
   "source": [
    "### Baseline  Naive Bayes using LabelPowerSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b8181311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier_power_nb = LabelPowerset(GaussianNB())\n",
    "# train\n",
    "classifier_power_nb.fit(selected_train[features], selected_train[labels])\n",
    "# predict\n",
    "predictions_power_nb = classifier_power_nb.predict(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fbbbcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "predictions_proba_power_nb = classifier_power_nb.predict_proba(selected_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29f58b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8656021457533011\n",
      "Precision score:  0.5987943558266151\n",
      "Recall score:  0.5372670807453416\n",
      "F1 score:  0.553592035258963\n",
      "Confusion matrix for label toxic:\n",
      "[[140607   3670]\n",
      " [  8174   7120]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[156415   1561]\n",
      " [   857    738]]\n",
      "Confusion matrix for label obscene:\n",
      "[[147546   3576]\n",
      " [  2595   5854]]\n",
      "Confusion matrix for label threat:\n",
      "[[154431   4662]\n",
      " [   189    289]]\n",
      "Confusion matrix for label insult:\n",
      "[[149165   2529]\n",
      " [  3482   4395]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[153987   4179]\n",
      " [   944    461]]\n",
      "Logarithmic Loss:  0.7372777504710718\n",
      "ROC AUC score:  0.9422719716163704\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "get_evaluation_score(selected_train[labels], predictions_power_nb, predictions_proba_power_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "633aaa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8111069430116603\n",
      "Precision score:  0.43116617623536224\n",
      "Recall score:  0.5779417850738033\n",
      "F1 score:  0.4836571435450641\n",
      "Confusion matrix for label toxic:\n",
      "[[54235  3653]\n",
      " [ 2620  3470]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[62171  1440]\n",
      " [  200   167]]\n",
      "Confusion matrix for label obscene:\n",
      "[[56730  3557]\n",
      " [ 1189  2502]]\n",
      "Confusion matrix for label threat:\n",
      "[[61769  1998]\n",
      " [   87   124]]\n",
      "Confusion matrix for label insult:\n",
      "[[58579  1972]\n",
      " [ 1594  1833]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[60119  3147]\n",
      " [  429   283]]\n",
      "Logarithmic Loss:  0.6426103750949465\n",
      "ROC AUC score:  0.9285302105506413\n"
     ]
    }
   ],
   "source": [
    "# evaluation on test data\n",
    "predictions_power_nb_test = classifier_power_nb.predict(selected_test[features])\n",
    "predictions_proba_power_nb_test = classifier_power_nb.predict_proba(selected_test[features])\n",
    "get_evaluation_score(selected_test[labels], predictions_power_nb_test, predictions_proba_power_nb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad51135",
   "metadata": {},
   "source": [
    "### Baseline  Naive Bayes using OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e9b0846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing toxic comments...**\n",
      "Test accuracy is 0.9051392666229017\n",
      "Test precision is 0.5011644671176666\n",
      "Test f1-score is 0.598265704640233\n",
      "Test recall is 0.7420361247947455\n",
      "[[53390  4498]\n",
      " [ 1571  4519]]\n",
      "Test logarithmic loss is 3.4191273940815905\n",
      "Test ROC-AUC score is 0.8321671779308166\n",
      "\n",
      "\n",
      "**Processing severe_toxic comments...**\n",
      "Test accuracy is 0.9293507143080434\n",
      "Test precision is 0.06293411913281415\n",
      "Test f1-score is 0.11684251660805002\n",
      "Test recall is 0.8147138964577657\n",
      "[[59159  4452]\n",
      " [   68   299]]\n",
      "Test logarithmic loss is 2.546458365669597\n",
      "Test ROC-AUC score is 0.8723630006412014\n",
      "\n",
      "\n",
      "**Processing obscene comments...**\n",
      "Test accuracy is 0.9170652411766544\n",
      "Test precision is 0.38647546745395756\n",
      "Test f1-score is 0.5088855979266939\n",
      "Test recall is 0.7447846112164725\n",
      "[[55923  4364]\n",
      " [  942  2749]]\n",
      "Test logarithmic loss is 2.989271700938692\n",
      "Test ROC-AUC score is 0.836198764712189\n",
      "\n",
      "\n",
      "**Processing threat comments...**\n",
      "Test accuracy is 0.9305542530244771\n",
      "Test precision is 0.034740545294635\n",
      "Test f1-score is 0.06640050430762764\n",
      "Test recall is 0.7488151658767772\n",
      "[[59377  4390]\n",
      " [   53   158]]\n",
      "Test logarithmic loss is 2.503078433334076\n",
      "Test ROC-AUC score is 0.8399853896409151\n",
      "\n",
      "\n",
      "**Processing insult comments...**\n",
      "Test accuracy is 0.9161743099190347\n",
      "Test precision is 0.35461099429258036\n",
      "Test f1-score is 0.4682201289043134\n",
      "Test recall is 0.6889407645170703\n",
      "[[56254  4297]\n",
      " [ 1066  2361]]\n",
      "Test logarithmic loss is 3.02138411838187\n",
      "Test ROC-AUC score is 0.808987896420151\n",
      "\n",
      "\n",
      "**Processing identity_hate comments...**\n",
      "Test accuracy is 0.9177998687048673\n",
      "Test precision is 0.08791009606670291\n",
      "Test f1-score is 0.155723230052978\n",
      "Test recall is 0.6811797752808989\n",
      "[[58234  5032]\n",
      " [  227   485]]\n",
      "Test logarithmic loss is 2.962793040941685\n",
      "Test ROC-AUC score is 0.8008212915540839\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using pipeline for applying naive bayes and one vs rest classifier\n",
    "NaiveBayes_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(GaussianNB(), n_jobs=-1)),\n",
    "            ])\n",
    "for category in labels:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    NaiveBayes_pipeline.fit(selected_train[features], selected_train[category])\n",
    "    \n",
    "    # calculating test accuracy (on test dataset)\n",
    "    prediction = NaiveBayes_pipeline.predict(selected_test[features])\n",
    "    print('Test accuracy is {}'.format(accuracy_score(selected_test[category], prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(selected_test[category], prediction)))\n",
    "    print('Test f1-score is {}'.format(f1_score(selected_test[category], prediction)))\n",
    "    print('Test recall is {}'.format(recall_score(selected_test[category], prediction)))\n",
    "    print(confusion_matrix(selected_test[category], prediction))\n",
    "    print('Test logarithmic loss is {}'.format(log_loss(selected_test[category], prediction)))\n",
    "    print('Test ROC-AUC score is {}'.format(roc_auc_score(selected_test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f7d53",
   "metadata": {},
   "source": [
    "### -- end -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2c2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
