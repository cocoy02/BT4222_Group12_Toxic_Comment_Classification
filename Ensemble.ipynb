{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be7174a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Import saved models\n",
    "import joblib\n",
    "\n",
    "# for KF validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "# for multi-label classification\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "#for LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# for random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# for xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#for evaluation\n",
    "# for evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# for evaluation metrics\n",
    "%run -i helper_functions.py\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a93bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model name\t\t                    f1_weighted\tlog_loss\troc_auc_weighted\n",
    "Baseline CNN                        0.725218    0.275093    0.981135\n",
    "Random Forest with BinaryRelevance\t0.657563\t0.321771\t0.966760\n",
    "Tuned LightGBM with BinaryRelevance\t0.690020\t0.296583\t0.969507\n",
    "Tuned XGBoost with BinaryRelevance\t0.694385\t0.307418\t0.966565\n",
    "Adaboost with BinaryRelevance\t\t0.669831\t0.387925\t0.963709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ec2c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train data\n",
    "selected_train = pd.read_csv('Data\\selected_train.csv')\n",
    "X_train =  selected_train[selected_train.columns[7:]]\n",
    "y_train = selected_train[selected_train.columns[:6]]\n",
    "\n",
    "#loading the test dataset\n",
    "selected_test = pd.read_csv('Data/selected_test.csv')\n",
    "X_test = selected_test[selected_train.columns[7:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87489063",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_xgb_br = BinaryRelevance(XGBClassifier(random_state=0, scale_pos_weight=5, max_depth=8, min_child_weight=3, gamma=0.4, colsample_bytree=1.0, subsample=1.0))\n",
    "tuned_lgbm_br = BinaryRelevance(LGBMClassifier(random_state=0, n_estimators=80, max_depth=6, min_split_gain=0.2, subsample=0.6))\n",
    "ada_br = BinaryRelevance(AdaBoostClassifier(random_state=0))\n",
    "rf_br = BinaryRelevance(RandomForestClassifier(random_state = 0,class_weight='balanced',max_depth = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7095e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(models, X_train, y_train, X_test, weights):\n",
    "    models_proba = []\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_proba = model.predict_proba(X_test)\n",
    "        models_proba.append(predictions_proba)\n",
    "\n",
    "    ##### Weigthed Average\n",
    "    weighted_average = (weights[0]*models_proba[0]+\n",
    "                        weights[1]*models_proba[1]+\n",
    "                        weights[2]*models_proba[2])\n",
    "\n",
    "    weighted_average_proba_df = pd.DataFrame.sparse.from_spmatrix(weighted_average, columns=selected_train.columns[:6])\n",
    "\n",
    "    #### Get label\n",
    "    predictions = weighted_average_proba_df\n",
    "    for label in y_train.columns:\n",
    "        predictions[label] = np.where(predictions[label] >= 0.5, 1, 0)\n",
    "    \n",
    "    return {'predictions': predictions, 'predict_proba': weighted_average_proba_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52bfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overwrite model_evaluation function from helper.py\n",
    "\n",
    "def model_evaluation(models, train, weights):\n",
    "    features = train.columns[7:]\n",
    "    labels = train.columns[:6]\n",
    "    kf = KFold(n_splits=5)\n",
    "    validation_scores = pd.DataFrame({'accuracy':[], 'precision_weighted':[], 'recall_weighted':[], \n",
    "                                      'f1_weighted':[], 'log_loss':[], 'roc_auc_weighted':[]})\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        train_split = train.iloc[train_index]\n",
    "        test_split = train.iloc[test_index]\n",
    "        print('Starting fitting...')\n",
    "        output = weighted_average(models, train_split[features], train_split[labels], test_split[features], weights)\n",
    "        predictions_proba = output['predict_proba']\n",
    "        predictions = output['predictions']\n",
    "\n",
    "        \n",
    "        scores = [accuracy_score(test_split[labels], predictions), precision_score(test_split[labels], predictions, average=\"weighted\"),\n",
    "                  recall_score(test_split[labels], predictions, average=\"weighted\"), \n",
    "                  f1_score(test_split[labels], predictions, average=\"weighted\"),\n",
    "                  log_loss(test_split[labels], predictions_proba), \n",
    "                  roc_auc_score(test_split[labels], predictions_proba, average=\"weighted\")]\n",
    "        validation_scores.loc[len(validation_scores)] = scores\n",
    "        print(f'Evaluation Scores:\\n{scores}\\n')\n",
    "    return validation_scores   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ae705",
   "metadata": {},
   "source": [
    "# Ensemble 1 (LGBM, XGBoost, and AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bbed17b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "[0.9119222935923547, 0.754946406353802, 0.6651691702934157, 0.7021977828639927, 1.4057302468285604, 0.8255746828331806]\n",
      "\n",
      "Starting fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "[0.9134549100708154, 0.7502204823653467, 0.66490501356949, 0.7018691335681302, 1.3289470452669154, 0.8255971886659689]\n",
      "\n",
      "Starting fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "[0.9148022811305383, 0.757293095682153, 0.6647662485746865, 0.7052760821303976, 1.3712369795827541, 0.8256343876074247]\n",
      "\n",
      "Starting fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "[0.9133922416494329, 0.747938829398676, 0.6738006320022982, 0.7029314833343828, 1.3302525631726532, 0.8294960570341356]\n",
      "\n",
      "Starting fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vanes\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      "[0.9134549100708154, 0.7523341611602621, 0.6568038879359634, 0.6960963316245494, 1.406448845288263, 0.8215171570131606]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_1 = [tuned_xgb_br, tuned_lgbm_br, ada_br]\n",
    "ensemble_1 = model_evaluation(models_1, selected_train, [1/3, 1/3, 1/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "35a6df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.911922</td>\n",
       "      <td>0.754946</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.702198</td>\n",
       "      <td>1.405730</td>\n",
       "      <td>0.825575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913455</td>\n",
       "      <td>0.750220</td>\n",
       "      <td>0.664905</td>\n",
       "      <td>0.701869</td>\n",
       "      <td>1.328947</td>\n",
       "      <td>0.825597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914802</td>\n",
       "      <td>0.757293</td>\n",
       "      <td>0.664766</td>\n",
       "      <td>0.705276</td>\n",
       "      <td>1.371237</td>\n",
       "      <td>0.825634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.913392</td>\n",
       "      <td>0.747939</td>\n",
       "      <td>0.673801</td>\n",
       "      <td>0.702931</td>\n",
       "      <td>1.330253</td>\n",
       "      <td>0.829496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913455</td>\n",
       "      <td>0.752334</td>\n",
       "      <td>0.656804</td>\n",
       "      <td>0.696096</td>\n",
       "      <td>1.406449</td>\n",
       "      <td>0.821517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_weighted  recall_weighted  f1_weighted  log_loss  \\\n",
       "0  0.911922            0.754946         0.665169     0.702198  1.405730   \n",
       "1  0.913455            0.750220         0.664905     0.701869  1.328947   \n",
       "2  0.914802            0.757293         0.664766     0.705276  1.371237   \n",
       "3  0.913392            0.747939         0.673801     0.702931  1.330253   \n",
       "4  0.913455            0.752334         0.656804     0.696096  1.406449   \n",
       "\n",
       "   roc_auc_weighted  \n",
       "0          0.825575  \n",
       "1          0.825597  \n",
       "2          0.825634  \n",
       "3          0.829496  \n",
       "4          0.821517  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b82f35c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9119222935923547, 0.7548049521047272, 0.6654499508634003, 0.7023500447420293, 1.4067145375433694, 0.8257111497132608]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9135175784921978, 0.7502455869048043, 0.66490501356949, 0.7018781402906501, 1.3289761457636213, 0.8255971886659689]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9146769442877734, 0.7571111342619925, 0.6653363740022805, 0.7054990718595194, 1.3690261996771658, 0.8258933690712769]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9135175784921978, 0.7483990289562756, 0.6743751795461075, 0.7034950748416028, 1.3269237742807614, 0.8297833308060402]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9134549100708154, 0.7514657382906181, 0.657661520869068, 0.6963729172506641, 1.404309289832919, 0.8219223825705774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Different weight - more weight on models with higher F1 and lower log loss score\n",
    "ensemble_3 = model_evaluation(models_1, selected_train, [3/8, 3/8, 1/4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8b3dab03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.911922</td>\n",
       "      <td>0.754805</td>\n",
       "      <td>0.665450</td>\n",
       "      <td>0.702350</td>\n",
       "      <td>1.406715</td>\n",
       "      <td>0.825711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913518</td>\n",
       "      <td>0.750246</td>\n",
       "      <td>0.664905</td>\n",
       "      <td>0.701878</td>\n",
       "      <td>1.328976</td>\n",
       "      <td>0.825597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914677</td>\n",
       "      <td>0.757111</td>\n",
       "      <td>0.665336</td>\n",
       "      <td>0.705499</td>\n",
       "      <td>1.369026</td>\n",
       "      <td>0.825893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.913518</td>\n",
       "      <td>0.748399</td>\n",
       "      <td>0.674375</td>\n",
       "      <td>0.703495</td>\n",
       "      <td>1.326924</td>\n",
       "      <td>0.829783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913455</td>\n",
       "      <td>0.751466</td>\n",
       "      <td>0.657662</td>\n",
       "      <td>0.696373</td>\n",
       "      <td>1.404309</td>\n",
       "      <td>0.821922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_weighted  recall_weighted  f1_weighted  log_loss  \\\n",
       "0  0.911922            0.754805         0.665450     0.702350  1.406715   \n",
       "1  0.913518            0.750246         0.664905     0.701878  1.328976   \n",
       "2  0.914677            0.757111         0.665336     0.705499  1.369026   \n",
       "3  0.913518            0.748399         0.674375     0.703495  1.326924   \n",
       "4  0.913455            0.751466         0.657662     0.696373  1.404309   \n",
       "\n",
       "   roc_auc_weighted  \n",
       "0          0.825711  \n",
       "1          0.825597  \n",
       "2          0.825893  \n",
       "3          0.829783  \n",
       "4          0.821922  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381ee62",
   "metadata": {},
   "source": [
    "# Ensemble 1 (LGBM, XGBoost, and RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8b493faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9088829703900987, 0.7171212386129368, 0.7063035237961534, 0.710014204513782, 1.19710448628984, 0.8444041618780586]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9087234442564391, 0.7116427769060432, 0.7026139122982431, 0.7055123418600046, 1.1745058481850823, 0.8425881809276611]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9105094942658395, 0.7239011433602807, 0.7092360319270239, 0.715950358446648, 1.1864606764488084, 0.846191897954615]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.910039481105471, 0.7133286019863341, 0.7150244182706119, 0.7120469817612871, 1.1371533756642025, 0.848465472953013]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9099768126840885, 0.715856514948613, 0.7012578616352201, 0.7065125100938601, 1.2092403059317378, 0.8419053972410111]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_2 = [tuned_xgb_br, tuned_lgbm_br, rf_br]\n",
    "ensemble_2_score = model_evaluation(models_2, selected_train, [1/3, 1/3, 1/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b1bd59b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.908883</td>\n",
       "      <td>0.717121</td>\n",
       "      <td>0.706304</td>\n",
       "      <td>0.710014</td>\n",
       "      <td>1.197104</td>\n",
       "      <td>0.844404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908723</td>\n",
       "      <td>0.711643</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.705512</td>\n",
       "      <td>1.174506</td>\n",
       "      <td>0.842588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.910509</td>\n",
       "      <td>0.723901</td>\n",
       "      <td>0.709236</td>\n",
       "      <td>0.715950</td>\n",
       "      <td>1.186461</td>\n",
       "      <td>0.846192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.910039</td>\n",
       "      <td>0.713329</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>0.712047</td>\n",
       "      <td>1.137153</td>\n",
       "      <td>0.848465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.909977</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.706513</td>\n",
       "      <td>1.209240</td>\n",
       "      <td>0.841905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_weighted  recall_weighted  f1_weighted  log_loss  \\\n",
       "0  0.908883            0.717121         0.706304     0.710014  1.197104   \n",
       "1  0.908723            0.711643         0.702614     0.705512  1.174506   \n",
       "2  0.910509            0.723901         0.709236     0.715950  1.186461   \n",
       "3  0.910039            0.713329         0.715024     0.712047  1.137153   \n",
       "4  0.909977            0.715857         0.701258     0.706513  1.209240   \n",
       "\n",
       "   roc_auc_weighted  \n",
       "0          0.844404  \n",
       "1          0.842588  \n",
       "2          0.846192  \n",
       "3          0.848465  \n",
       "4          0.841905  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eb40f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9105749647501175, 0.7314768597251409, 0.6945107398568019, 0.7102751027921048, 1.264944571182985, 0.8391750636619557]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9104781600551483, 0.722356029386905, 0.6906156263390945, 0.7045121751153328, 1.2223511036683345, 0.8371951699265464]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9118255311148712, 0.7355584749098699, 0.6954104903078677, 0.7140208847251024, 1.2422051805621837, 0.8398707493019653]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9111048442689729, 0.7225871718444269, 0.7032461936225223, 0.7099529325522982, 1.2011140143614047, 0.8430543195020472]\n",
      "\n",
      "Starting fitting...\n",
      "Evaluation Scores:\n",
      "[0.9109168390048255, 0.7271791476540261, 0.6878216123499142, 0.7043033239411101, 1.268764095733869, 0.8357408781202781]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_2 = [tuned_xgb_br, tuned_lgbm_br, rf_br]\n",
    "ensemble_4_score = model_evaluation(models_2, selected_train, [3/8, 3/8, 1/4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b87341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_4_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2087077",
   "metadata": {},
   "source": [
    "### Store the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a616ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_collection = pd.DataFrame({'model name': [], 'accuracy':[], 'precision_weighted':[], 'recall_weighted':[], \n",
    "                                      'f1_weighted':[], 'log_loss':[], 'roc_auc_weighted':[]})\n",
    "scores_collection.loc[len(scores_collection)] = ['Ensemble 1 (XGBoost, LGBM, AdaBoost) with equal weight']+np.mean(ensemble_1).values.tolist()\n",
    "scores_collection.loc[len(scores_collection)] = ['Ensemble 2 (XGBoost, LGBM, AdaBoost) with different weight']+np.mean(ensemble_3).values.tolist()\n",
    "scores_collection.loc[len(scores_collection)] = ['Ensemble 3 (XGBoost, LGBM, RandomForest) with equal weight']+np.mean(ensemble_2_score).values.tolist()\n",
    "scores_collection.loc[len(scores_collection)] = ['Ensemble 4 (XGBoost, LGBM, RandomForest) with different weight']+np.mean(ensemble_4_score).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40e007f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble 1 (XGBoost, LGBM, AdaBoost) with equa...</td>\n",
       "      <td>0.913405</td>\n",
       "      <td>0.752546</td>\n",
       "      <td>0.665089</td>\n",
       "      <td>0.701674</td>\n",
       "      <td>1.368523</td>\n",
       "      <td>0.825564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble 2 (XGBoost, LGBM, AdaBoost) with diff...</td>\n",
       "      <td>0.913418</td>\n",
       "      <td>0.752405</td>\n",
       "      <td>0.665546</td>\n",
       "      <td>0.701919</td>\n",
       "      <td>1.367190</td>\n",
       "      <td>0.825780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ensemble 3 (XGBoost, LGBM, RandomForest) with ...</td>\n",
       "      <td>0.909626</td>\n",
       "      <td>0.716370</td>\n",
       "      <td>0.706887</td>\n",
       "      <td>0.710007</td>\n",
       "      <td>1.180893</td>\n",
       "      <td>0.844709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble 4 (XGBoost, LGBM, RandomForest) with ...</td>\n",
       "      <td>0.910980</td>\n",
       "      <td>0.727832</td>\n",
       "      <td>0.694321</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>1.239876</td>\n",
       "      <td>0.839007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model name  accuracy  \\\n",
       "0  Ensemble 1 (XGBoost, LGBM, AdaBoost) with equa...  0.913405   \n",
       "1  Ensemble 2 (XGBoost, LGBM, AdaBoost) with diff...  0.913418   \n",
       "2  Ensemble 3 (XGBoost, LGBM, RandomForest) with ...  0.909626   \n",
       "3  Ensemble 4 (XGBoost, LGBM, RandomForest) with ...  0.910980   \n",
       "\n",
       "   precision_weighted  recall_weighted  f1_weighted  log_loss  \\\n",
       "0            0.752546         0.665089     0.701674  1.368523   \n",
       "1            0.752405         0.665546     0.701919  1.367190   \n",
       "2            0.716370         0.706887     0.710007  1.180893   \n",
       "3            0.727832         0.694321     0.708613  1.239876   \n",
       "\n",
       "   roc_auc_weighted  \n",
       "0          0.825564  \n",
       "1          0.825780  \n",
       "2          0.844709  \n",
       "3          0.839007  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ba54803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save scores dataframe\n",
    "scores_collection.to_csv('Ensemble Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18c553",
   "metadata": {},
   "source": [
    "## Evaluate on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aca0a2",
   "metadata": {},
   "source": [
    "Evalute the best performing ensemble model, Ensemble 3, based on its validation score (F1 and log loss) on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccb6cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the best performing ensemble model on test dataset\n",
    "test_output_prediction = weighted_average(models_2, X_train, y_train, X_test, [1/3,1/3,1/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99d33a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.867704523429929\n",
      "Precision score:  0.5284269189758418\n",
      "Recall score:  0.7473444613050075\n",
      "F1 score:  0.6160023199223558\n",
      "Confusion matrix for label toxic:\n",
      "[[53652  4236]\n",
      " [ 1151  4939]]\n",
      "Confusion matrix for label severe_toxic:\n",
      "[[63129   482]\n",
      " [  153   214]]\n",
      "Confusion matrix for label obscene:\n",
      "[[57846  2441]\n",
      " [  803  2888]]\n",
      "Confusion matrix for label threat:\n",
      "[[63673    94]\n",
      " [  141    70]]\n",
      "Confusion matrix for label insult:\n",
      "[[58423  2128]\n",
      " [  957  2470]]\n",
      "Confusion matrix for label identity_hate:\n",
      "[[62986   280]\n",
      " [  458   254]]\n",
      "Logarithmic Loss:  1.233934206156114\n",
      "ROC AUC score:  0.8487802053438396\n"
     ]
    }
   ],
   "source": [
    "get_evaluation_score(selected_test[selected_test.columns[:6]], scipy.sparse.csr_matrix(test_output_prediction['predictions'].values), test_output_prediction['predict_proba'].to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
